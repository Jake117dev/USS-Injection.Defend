"""
prompt_builder.py

Erzeugt den finalen Prompt-Kontext zur Ãœbergabe an das LLM:
- Inklusive Schutz vor Strukturbruch
- Optionaler LÃ¤ngenbegrenzer fÃ¼r Eingaben
- Audit-Hash zur Wiedererkennung
"""

import hashlib
import textwrap

MAX_USER_CHARS = 3000
MAX_DATA_CHARS = 5000

def sanitize_block(text: str) -> str:
    """
    Entfernt gefÃ¤hrliche Steuerzeichen und Prompt-Marker.
    """
    text = text.replace("###", "# # #")
    return text.strip()

def shorten(text: str, max_len: int) -> str:
    """
    KÃ¼rzt zu lange Texte auf max_len Zeichen.
    """
    if len(text) > max_len:
        return textwrap.shorten(text, width=max_len, placeholder="...[truncated]")
    return text

def build_prompt(system_prompt: str, user_prompt: str, clean_data: str = "") -> dict:
    """
    Erzeugt finalen Prompt. RÃ¼ckgabe:
    {
        'prompt': str,
        'hash': str,
        'meta': dict
    }
    """

    # Sanitize + KÃ¼rzen
    system_block = sanitize_block(system_prompt)
    user_block = shorten(sanitize_block(user_prompt), MAX_USER_CHARS)
    data_block = shorten(sanitize_block(clean_data), MAX_DATA_CHARS) if clean_data else "[No external data provided]"

    prompt = f"""### SYSTEM ###
{system_block}

### USER ###
{user_block}

### DATA (filtered input) ###
{data_block}
"""

    # Hash fÃ¼r Audit-Zwecke
    prompt_hash = hashlib.sha256(prompt.encode("utf-8")).hexdigest()

    print("[PromptBuilder] Finaler Prompt erzeugt.")
    return {
        "prompt": prompt,
        "hash": prompt_hash,
        "meta": {
            "user_len": len(user_block),
            "data_len": len(data_block),
            "truncated": len(user_prompt) > MAX_USER_CHARS or len(clean_data) > MAX_DATA_CHARS
        }
    }

"""
ğŸš€ Vorteile

Feature	                            Effekt

ğŸ§± Struktur-Schutz	                "###" wird entschÃ¤rft â†’ kein Fake-Systemblock
âœ‚ï¸ TextkÃ¼rzung	                    Verhindert Overflow von KontextlÃ¤nge
ğŸ” SHA-256-Hash	                    FÃ¼r Audit, Logging, oder Session-Wiederherstellung
ğŸ“¦ RÃ¼ckgabe als Dict	            Macht Weiterverarbeitung sauber & strukturiert
ğŸ“ Meta-Daten	                    Zeigt, ob Inhalt gekÃ¼rzt wurde

ğŸ” Integrationstipp
Im Agenten-Stack kann man damit z.â€¯B. nachvollziehen:

Welche Prompts zu welchen LLM-Antworten fÃ¼hrten

Welche Session wie oft truncated == True getriggert hat (â†’ evtl. Split nÃ¶tig)
"""

